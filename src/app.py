import streamlit as st
import torch
import re
import time
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification
from transformers_interpret import SequenceClassificationExplainer
from pathlib import Path

# --- 1. KONFIGURACJA STRONY ---
st.set_page_config(
    page_title="System Weryfikacji Treci",
    page_icon="",
    layout="wide" # Szeroki ukad dla lepszej czytelnoci wykres贸w
)

# Style CSS (usunicie zbdnych odstp贸w, czytelna czcionka)
st.markdown("""
    <style>
        .block-container { padding-top: 2rem; }
        h1 { font-size: 2.2rem; }
        .stAlert { padding: 0.5rem; }
        .highlight-text { line-height: 1.6; font-family: monospace; font-size: 14px; }
    </style>
""", unsafe_allow_html=True)

st.title("System Klasyfikacji Wiarygodnoci Artyku贸w")
st.markdown("Narzdzie wykorzystuje architektur **BERT** do oceny wiarygodnoci tekstu oraz **Explainable AI** do analizy wpywu poszczeg贸lnych token贸w na decyzj modelu.")
st.divider()

# --- 2. LOGIKA BACKENDU ---

def clean_text_standard(text):
    """Standardyzacja tekstu wejciowego (zgodna z treningiem)."""
    if not isinstance(text, str): return ""
    text = text.lower()
    text = re.sub(r'http\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Mapowanie klas (0=Real, 1=Fake)
LABELS = {0: "WIARYGODNY (REAL)", 1: "FASZYWY (FAKE)"}

@st.cache_resource
def load_inference_engine():
    model_path = Path(__file__).resolve().parent.parent / "model"
    model_path_str = str(model_path)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        if not model_path.exists():
            raise FileNotFoundError(f"Model directory not found: {model_path_str}")

        tokenizer = BertTokenizer.from_pretrained(model_path_str)
        model = BertForSequenceClassification.from_pretrained(model_path_str)
        model.to(device)
        model.eval()
        
        # Inicjalizacja explainera
        explainer = SequenceClassificationExplainer(model, tokenizer)
        return tokenizer, model, device, explainer
    except Exception as e:
        st.error(f"Bd inicjalizacji modelu: {e}")
        return None, None, None, None

tokenizer, model, device, cls_explainer = load_inference_engine()

# --- 3. FUNKCJA WIZUALIZACJI ---
def visualize_attributions(attributions, prediction_label):
    """
    Rczne generowanie HTML dla atrybucji, aby unikn bd贸w biblioteki.
    Sowa wpywajce na predykcj s podwietlane.
    """
    html_content = '<div class="highlight-text">'
    
    # Normalizacja kolor贸w
    # Jeli wynik to FAKE (1), to tokeny popychajce do FAKE s czerwone.
    # Jeli wynik to REAL (0), to tokeny popychajce do REAL s zielone.
    
    for word, score in attributions:
        # Pomi tokeny specjalne
        if word in ['[CLS]', '[SEP]']:
            continue
            
        clean_word = word.replace('##', '') # Usunicie artefakt贸w tokenizacji BERTa
        
        # Ustalenie koloru ta na podstawie wagi (score)
        # Score > 0 oznacza, 偶e sowo wspiera wybran klas
        alpha = min(abs(score) * 5, 1.0) # Wzmocnienie koloru dla widocznoci
        
        if prediction_label == 1: # FAKE
            if score > 0:
                color = f"rgba(255, 0, 0, {alpha})" # Czerwony (Wspiera Fake)
            else:
                color = f"rgba(0, 255, 0, {alpha})" # Zielony (Przeczy Fake)
        else: # REAL
            if score > 0:
                color = f"rgba(0, 255, 0, {alpha})" # Zielony (Wspiera Real)
            else:
                color = f"rgba(255, 0, 0, {alpha})" # Czerwony (Przeczy Real)

        # Jeli waga jest znikoma, brak ta
        if abs(score) < 0.05:
            html_content += f'<span>{clean_word} </span>'
        else:
            html_content += f'<span style="background-color: {color}; border-radius: 3px; padding: 0 2px;">{clean_word}</span> '
            
    html_content += '</div>'
    return html_content

# --- 4. INTERFEJS U呕YTKOWNIKA ---

col_input, col_stats = st.columns([2, 1])

with col_input:
    user_text = st.text_area("Wprowad藕 tekst artykuu (jzyk angielski):", height=250)
    analyze_btn = st.button("Uruchom analiz", type="primary")

# Kontener na wyniki
if analyze_btn and user_text and model:
    start_time = time.time()
    
    with st.spinner("Przetwarzanie..."):
        # 1. Preprocessing
        cleaned_text = clean_text_standard(user_text)
        
        # 2. Tokenizacja i Predykcja
        inputs = tokenizer(cleaned_text, return_tensors="pt", truncation=True, padding=True, max_length=512).to(device)
        
        with torch.no_grad():
            outputs = model(**inputs)
            probs = F.softmax(outputs.logits, dim=1)
            pred_idx = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_idx].item()
            
            # Pobranie prawdopodobiestw dla obu klas
            prob_real = probs[0][0].item()
            prob_fake = probs[0][1].item()

        # 3. Explainability (Obliczanie wag)
        attributions = cls_explainer(cleaned_text)
        
    end_time = time.time()
    inference_time = (end_time - start_time) * 1000

    # --- PREZENTACJA WYNIKW ---
    
    # Prawa kolumna - Metryki techniczne
    with col_stats:
        st.subheader("Metryki Modelu")
        st.info(f"Czas inferencji: {inference_time:.1f} ms")
        st.text(f"Liczba token贸w: {len(tokenizer.encode(cleaned_text))}")
        st.text(f"Urzdzenie: {str(device).upper()}")
        
        st.write("Rozkad prawdopodobiestwa:")
        st.progress(prob_real, text=f"REAL: {prob_real:.2%}")
        st.progress(prob_fake, text=f"FAKE: {prob_fake:.2%}")

    # Lewa kolumna - G贸wny wynik i Wyjanienie
    with col_input:
        st.subheader("Wynik Klasyfikacji")
        
        if pred_idx == 1:
            st.error(f"**{LABELS[1]}** (Pewno: {confidence:.2%})")
        else:
            st.success(f"**{LABELS[0]}** (Pewno: {confidence:.2%})")

        st.divider()
        st.subheader("Analiza Atrybucji Token贸w")
        st.caption("Poni偶szy tekst wizualizuje wpyw poszczeg贸lnych s贸w na decyzj modelu. Kolor intensywny oznacza silny wpyw na wybran klas.")
        
        # Generowanie i wywietlanie wizualizacji (Manual HTML)
        html_viz = visualize_attributions(attributions, pred_idx)
        st.markdown(html_viz, unsafe_allow_html=True)
